{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7vl14vY17Xx"
   },
   "source": [
    "### Homework #3: ML workflow and target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eN7XrCe217X4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HtFOlGCU17X8",
    "outputId": "a6edf2e5-204d-4586-fa22-a9f0b762e6c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHgnBqr717X-"
   },
   "source": [
    "We will solve a regression problem: it is necessary to predict the **quality of wine** based on its characteristics.\n",
    "\n",
    "### Step 1. (**0.2 points**)\n",
    "\n",
    "Create the feature matrix **X** (object-feature) and the target vector **y** (\"quality\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OfN1V4Of17X-"
   },
   "outputs": [],
   "source": [
    "y = df.iloc[:, -1] \n",
    "X = df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QYaYYUh17X_"
   },
   "source": [
    "### Step 2. (**0.2 points**)\n",
    "\n",
    "Split the data into **train** and **test** sets (test data share — **30%**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3MOH47U517YA"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fORyaCO17YB"
   },
   "source": [
    "### Step 3. (**0.2 points**)\n",
    "\n",
    "Train a **linear regression** model on the training data and make predictions on both the **train** and **test** sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GViwO1Fy17YB"
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred_mse = reg.predict(X_test)\n",
    "y_pred_train_mse = reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEQur8eP17YC"
   },
   "source": [
    "### Step 4. (**0.4 points**)\n",
    "\n",
    "Display the **MSE error** on the **train** and **test** sets, then display the **R² score** on the **train** and **test** sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jKBk7fvn17YD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on training data: 0.4029193184207987\n",
      "MSE on test data: 0.4641292014818482\n",
      "R² on training data: 0.38369769677763454\n",
      "R² on test data: 0.28169107467930066\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = reg.predict(X_train)\n",
    "y_pred_test  = reg.predict(X_test)\n",
    "\n",
    "print(f\"MSE on training data: {mean_squared_error(y_train, y_pred_train):}\")\n",
    "print(f\"MSE on test data: {mean_squared_error(y_test, y_pred_test):}\")\n",
    "print(f\"R² on training data: {r2_score(y_train, y_pred_train):}\")\n",
    "print(f\"R² on test data: {r2_score(y_test, y_pred_test):}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejd9S4Q_17YD"
   },
   "source": [
    "### Step 5. (**0.5 points**)\n",
    "\n",
    "Calculate the **average quality (R²)** of the model using **cross-validation** with **k = 5 folds**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Abn-QTyM17YE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29004162884219536"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_scores = cross_val_score(reg, X, y, cv=5, scoring='r2')\n",
    "\n",
    "r2_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vniRLzAM17YE"
   },
   "source": [
    "### Step 6. (**0.5 points**)\n",
    "\n",
    "Now apply **linear regression with L1 regularization (Lasso)** to this task.\n",
    "Declare the model and tune the **regularization parameter α** using a grid search.\n",
    "Search for **α** in the range **(0.1, 1.1)** with a **step of 0.1**.\n",
    "\n",
    "Perform the tuning of **α** using the **training data (X_train, y_train)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.1, Train MSE: 0.4774, Train R²: 0.2698\n",
      "alpha=0.2, Train MSE: 0.5185, Train R²: 0.2070\n",
      "alpha=0.3, Train MSE: 0.5648, Train R²: 0.1361\n",
      "alpha=0.4, Train MSE: 0.6295, Train R²: 0.0371\n",
      "alpha=0.5, Train MSE: 0.6316, Train R²: 0.0339\n",
      "alpha=0.6, Train MSE: 0.6317, Train R²: 0.0338\n",
      "alpha=0.7, Train MSE: 0.6318, Train R²: 0.0336\n",
      "alpha=0.8, Train MSE: 0.6319, Train R²: 0.0334\n",
      "alpha=0.9, Train MSE: 0.6321, Train R²: 0.0332\n",
      "alpha=1.0, Train MSE: 0.6323, Train R²: 0.0329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "best_alpha = ''\n",
    "best_r2 = float('inf')  \n",
    "results = []\n",
    "\n",
    "for alpha in np.arange(0.1, 1.1, 0.1):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_tr = lasso.predict(X_train)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, y_pred_tr)\n",
    "    train_r2 = r2_score(y_train, y_pred_tr)\n",
    "\n",
    "    results.append((alpha, train_mse, train_r2)) \n",
    "\n",
    "    print(f'alpha={alpha:.1f}, Train MSE: {train_mse:.4f}, Train R²: {train_r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KZC5uOQ17YG"
   },
   "source": [
    "### Step 7. (**0.5 points**)\n",
    "\n",
    "Display the **best algorithm** and the **best quality** obtained from tuning **α** (`best_estimator_` and `best_score_`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HZBo6bZY17YG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator : Lasso(alpha=0.1)\n",
      "Best score (R²): 0.26162552533012484\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0.1, 1.1, 0.1) \n",
    "params = {'alpha': alphas}\n",
    "\n",
    "cv = GridSearchCV(lasso, params, scoring='r2', cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print('Best estimator :', cv.best_estimator_)\n",
    "print('Best score (R²):', cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJghumt117YH"
   },
   "source": [
    "### Step 8. (**0.5 points**)\n",
    "\n",
    "Using the obtained **best_estimator_**, make predictions on the **test data** and display the **R² score** on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BBMQvQs817YH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18860624128065862"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = cv.best_estimator_.predict(X_test)\n",
    "test_r2_score = r2_score(y_test, y_pred_test)\n",
    "\n",
    "test_r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sKZz1LK17YI"
   },
   "source": [
    "### Step 9. (**0.5 points**)\n",
    "\n",
    "Let’s try to improve model quality by adding **polynomial features**. Create a **pipeline** that first adds **degree-2 polynomial features**, then applies **linear regression**.\n",
    "\n",
    "Then compute the **R² score** of this model using **5-fold cross-validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xcgzVSsM17YI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.23009616946201242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "linear_pipe = Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "                       ('linear_model', LinearRegression())])\n",
    "print('R²:', cross_val_score(linear_pipe, X, y, cv=5, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHdHiMQ_17YJ"
   },
   "source": [
    "### Step 10. (**0.5 points**)\n",
    "\n",
    "Train the **pipeline model** on the **training data** and make predictions for both the **train** and **test** sets.\n",
    "Then display the **R² score** and **MSE** for the **training** and **test** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jBjwIal-17YK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on training data: 1.4544816422007008\n",
      "MSE on test data: 1.7487605012189913\n",
      "R² on training data: -1.2247639790424807\n",
      "R² on test data: -1.7064668033455512\n"
     ]
    }
   ],
   "source": [
    "linear_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_pipe = linear_pipe.predict(X_train)\n",
    "y_pred_test_pipe = linear_pipe.predict(X_test)\n",
    "\n",
    "print(f\"MSE on training data: {mean_squared_error(y_train, y_pred_train_pipe):}\")\n",
    "print(f\"MSE on test data: {mean_squared_error(y_test, y_pred_test_pipe):}\")\n",
    "print(f\"R² on training data: {r2_score(y_train, y_pred_train_pipe):}\")\n",
    "print(f\"R² on test data: {r2_score(y_test, y_pred_test_pipe):}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RYZ62Uo17YK"
   },
   "source": [
    "### Conclusions (1 point)\n",
    "\n",
    "1. **Evaluation of the linear model without regularization**\n",
    "   The linear model without regularization did not perform very well. An R² value below 0.5 indicates that the model does not explain much of the variance in wine quality. However, it’s difficult to claim definite overfitting — the test metric is only slightly worse (by about 0.1) than the training one. The difference between MSE and R² values across train and test is small, so there is no strong evidence of overfitting. Additionally, results vary slightly when the `random_state` parameter changes, which also suggests instability rather than overfitting.\n",
    "\n",
    "2. **Effect of L1 regularization on model quality**\n",
    "   L1 regularization (Lasso) did **not** improve model performance. The R² score dropped to around **0.26**, which is worse than the original linear regression. This indicates that regularization over-penalized the coefficients, reducing model flexibility without improving generalization. Hence, it didn’t fix potential overfitting and even decreased overall predictive power.\n",
    "\n",
    "3. **Effect of adding polynomial features**\n",
    "   Adding polynomial (degree-2) features **significantly worsened** model quality. On the training data, **R² became negative (-1.2248)**, meaning the model explains less variance than simply predicting the mean of the target variable. On the test data, the result was even worse (**R² = -1.7065**).\n",
    "\n",
    "This clearly shows **overfitting** — the model became too complex relative to the data. The large number of polynomial features caused the model to memorize noise in the training set, leading to a dramatic loss of generalization on unseen data. Thus, adding nonlinear terms made the model unstable and ineffective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o-lDGMS17YL"
   },
   "source": [
    "### *Attempt to improve the model (achieve the best possible quality)*\n",
    "\n",
    "When I was working on improving model performance, I came across an interesting method called the **Voting Regressor**.\n",
    "(I tried many options — this one was the only one that showed a relatively substantial improvement.)\n",
    "\n",
    "As I understand it, the **Voting Regressor** works as follows: it trains several models on the same dataset and then combines their predictions.\n",
    "For example, in my implementation I used a simple **Linear Regression** and a **Random Forest** — two quite different approaches.\n",
    "Instead of relying on just one of them, the **Voting Regressor** averages their predictions, which helps **reduce error and improve the model’s generalization ability**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "k527OrgK17YN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor R²: 0.37916548267789696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor\n",
    "\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('lr', LinearRegression()),\n",
    "    ('rf', RandomForestRegressor(n_estimators=100))\n",
    "])\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "y_pred_test_voting = voting_regressor.predict(X_test)\n",
    "\n",
    "print('Voting Regressor R²:', r2_score(y_test, y_pred_test_voting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AZ8ZwvP17YQ"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "X7oNha7017YS",
    "outputId": "3d61e9bf-5e85-438b-813a-a1626363265e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935844</th>\n",
       "      <td>10.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935845</th>\n",
       "      <td>09.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935846</th>\n",
       "      <td>14.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7459</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935847</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7440</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935848</th>\n",
       "      <td>03.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2935849 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  date_block_num  shop_id  item_id  item_price  target\n",
       "0        02.01.2013               0       59    22154      999.00     1.0\n",
       "1        03.01.2013               0       25     2552      899.00     1.0\n",
       "2        05.01.2013               0       25     2552      899.00    -1.0\n",
       "3        06.01.2013               0       25     2554     1709.05     1.0\n",
       "4        15.01.2013               0       25     2555     1099.00     1.0\n",
       "...             ...             ...      ...      ...         ...     ...\n",
       "2935844  10.10.2015              33       25     7409      299.00     1.0\n",
       "2935845  09.10.2015              33       25     7460      299.00     1.0\n",
       "2935846  14.10.2015              33       25     7459      349.00     1.0\n",
       "2935847  22.10.2015              33       25     7440      299.00     1.0\n",
       "2935848  03.10.2015              33       25     7460      299.00     1.0\n",
       "\n",
       "[2935849 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('sales_train.csv.gz')\n",
    "sales.columns = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'target']\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pf2RAhgG17YV"
   },
   "outputs": [],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = []\n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'target':'sum'})\n",
    "\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKxPEUME17YX"
   },
   "source": [
    "### Mean encodings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDJIXqPJ17YZ"
   },
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nP0txxgu17YZ",
    "outputId": "71675772-09fc-4c64-cbc5-28376a5966fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830386988621764\n"
     ]
    }
   ],
   "source": [
    "# Calculate a mapping: {item_id: target_mean}\n",
    "item_id_target_mean = all_data.groupby('item_id').target.mean()\n",
    "\n",
    "# In our non-regularized case we just *map* the computed means to the `item_id`'s\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mc7TQh6V17Yb"
   },
   "source": [
    "#### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ujgcz3um17Yc",
    "outputId": "e218ca20-126f-4806-a18f-89fa33b8eb6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830386988621764\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "     Differently to `.target.mean()` function `transform`\n",
    "   will return a dataframe with an index like in `all_data`.\n",
    "   Basically this single line of code is equivalent to the first two lines from of Method 1.\n",
    "'''\n",
    "all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRCBHEWe17Yd"
   },
   "source": [
    "### KFold scheme (**1.25 points**)\n",
    "\n",
    "You need to implement a KFold scheme with five folds. Use `KFold(5)` from `sklearn.model_selection`.\n",
    "\n",
    "1. Split the data into **5 folds** using `sklearn.model_selection.KFold` with the parameter `shuffle=False`.\n",
    "2. Iterate over the folds: use the **4 training folds** to compute the **mean target values by `item_id`**, and fill these values into the **validation fold** at each iteration.\n",
    "\n",
    "Pay attention to **Method 1** from the example. In particular, study how the functions `map` and `pd.Series.map` work — they are quite useful in many situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41645907127988446"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "item_target_enc = np.zeros(all_data.shape[0])\n",
    "\n",
    "for train_index, test_index in kf.split(all_data):\n",
    "    train_data = all_data.iloc[train_index]\n",
    "    test_data = all_data.iloc[test_index]\n",
    "    \n",
    "    item_id_target_mean = train_data.groupby('item_id')['target'].mean()\n",
    "    item_target_enc[test_index] = test_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "all_data['item_target_enc'] = item_target_enc\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "correlation = np.corrcoef(all_data['target'].values, all_data['item_target_enc'].values)[0][1]\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYVw71Yj17aG"
   },
   "source": [
    "### Leave-one-out scheme (**1.25 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ9BuEDM17aG"
   },
   "source": [
    "You need to implement a **leave-one-out** scheme. Note: if you run the code from the first task with the number of folds equal to the dataset size, you might get the correct result, but you’ll be waiting **a very, very long time**.\n",
    "\n",
    "For a faster way to compute the **mean target for all objects except one**, you can:\n",
    "\n",
    "1. Compute the **total (sum) of the target** over all objects.\n",
    "2. Subtract the target of the specific object and divide the result by `n_objects - 1`.\n",
    "\n",
    "Note that step **1** should be done for **all** objects. Also, step **2** can be implemented **without** `for` loops.\n",
    "\n",
    "The `.transform` function from **Method 2** in the example may be useful here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4803848311293092"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_target_sum = all_data.groupby('item_id')['target'].transform('sum')\n",
    "n_objects = all_data.groupby('item_id')['target'].transform('size')\n",
    "\n",
    "all_data['item_target_enc'] = (total_target_sum - all_data['target']) / (n_objects - 1)\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "zakodirovannaya = all_data['item_target_enc']\n",
    "correlation = np.corrcoef(all_data['target'], zakodirovannaya)[0, 1]\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Dzq8xW17aI"
   },
   "source": [
    "### Smoothing (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "pwjuyAnv17aI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция: 0.4818\n"
     ]
    }
   ],
   "source": [
    "localmean = all_data.groupby('item_id').target.mean()  \n",
    "nrows = all_data.groupby('item_id').target.count()\n",
    "\n",
    "all_data['item_target_enc'] = all_data['item_id'].map((localmean * nrows + 0.3343 * 100) / (nrows + 100))\n",
    "\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)  \n",
    "zakodirovannaya = all_data['item_target_enc'].values\n",
    "\n",
    "correlation = np.corrcoef(all_data['target'].values, zakodirovannaya)[0][1] \n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2gbXN7017aJ"
   },
   "source": [
    "Ожидаемый ответ 0.4818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4exEAIF17aJ"
   },
   "source": [
    "### Expanding mean схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inIMt53z17aJ"
   },
   "source": [
    "Необходимо реализовать *expanding mean* схему. Ее суть заключается в том, чтобы пройти по отсортированному в определенном порядке датасету (датасет сортируется в самом начале задания) и для подсчета счетчика для строки $m$ использовать строки от $0$ до $m-1$. Вам будет необходимо воспользоваться pandas функциями [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html) и [`cumcount`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.cumcount.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция: 0.5025\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data.sort_values(['date_block_num', 'shop_id', 'item_id'])\n",
    "\n",
    "cumulative_sum = all_data.groupby('item_id')['target'].cumsum()\n",
    "previous_target_sum = cumulative_sum - all_data['target']\n",
    "item_counts = all_data.groupby('item_id')['target'].cumcount()\n",
    "\n",
    "all_data['item_target_enc'] = previous_target_sum / item_counts\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "zakodirovannaya = all_data['item_target_enc'].values  \n",
    "\n",
    "correlation = np.corrcoef(all_data['target'].values, zakodirovannaya)[0][1] \n",
    "print(f'Корреляция: {correlation:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jH2vnZx17aK"
   },
   "source": [
    "Ожидаемый ответ 0.5025"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

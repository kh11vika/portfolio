{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7vl14vY17Xx"
   },
   "source": [
    "# Домашнее задание №2\n",
    "\n",
    "**Максимальная оценка за работу `min(X, 10)`, где X - суммарный балл за hw2 из 12 возможных.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTmabsBR17X3"
   },
   "source": [
    "## Часть 1. ML workflow (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eN7XrCe217X4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4bq1HnB17X7"
   },
   "source": [
    "### Загрузим данные для работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HtFOlGCU17X8",
    "outputId": "a6edf2e5-204d-4586-fa22-a9f0b762e6c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kh11vika/Downloads/winequality-red.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHgnBqr717X-"
   },
   "source": [
    "Будем решать задачу регрессии: необходимо предсказать качество вина на основе его характеристик\n",
    "\n",
    "### Шаг 1.  (**0.2 балла**)\n",
    "Создайте матрицу X объект-признак и целевой вектор y (\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "OfN1V4Of17X-"
   },
   "outputs": [],
   "source": [
    "y = df.iloc[:, -1] \n",
    "X = df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QYaYYUh17X_"
   },
   "source": [
    "### Шаг 2. (**0.2 балла**)\n",
    "Разбейте данные на train и test (доля тестовых данных - 30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "3MOH47U517YA"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fORyaCO17YB"
   },
   "source": [
    "### Шаг 3. (**0.2 балла**)\n",
    "Обучите линейную регрессию на тренировочных данных и сделайте предсказания на train и на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "GViwO1Fy17YB"
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred_mse = reg.predict(X_test)\n",
    "y_pred_train_mse = reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEQur8eP17YC"
   },
   "source": [
    "### Шаг 4. (**0.4 балла**)\n",
    "Выведите на экран ошибку MSE на train и на test, затем выведите на экран ошибку r2 на train и test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "jKBk7fvn17YD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE на тренировочных данных: 0.4029193184207987\n",
      "MSE на тестовых данных: 0.4641292014818482\n",
      "R² на тренировочных данных: 0.38369769677763454\n",
      "R² на тестовых данных: 0.28169107467930066\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = reg.predict(X_train)\n",
    "y_pred_test = reg.predict(X_test)\n",
    "\n",
    "print(f\"MSE на тренировочных данных: {mean_squared_error(y_train, y_pred_train):}\")\n",
    "print(f\"MSE на тестовых данных: {mean_squared_error(y_test, y_pred_test):}\")\n",
    "print(f\"R² на тренировочных данных: {r2_score(y_train, y_pred_train):}\")\n",
    "print(f\"R² на тестовых данных: {r2_score(y_test, y_pred_test):}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejd9S4Q_17YD"
   },
   "source": [
    "### Шаг 5. (**0.5 балла**)\n",
    "Вычислите среднее качество (r2) модели на кросс-валидации с k=5 фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Abn-QTyM17YE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее R² на кросс-валидации с 5 фолдами: 0.2900\n"
     ]
    }
   ],
   "source": [
    "r2_scores = cross_val_score(reg, X, y, cv=5, scoring='r2')\n",
    "\n",
    "print(f\"Среднее R² на кросс-валидации с 5 фолдами: {r2_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vniRLzAM17YE"
   },
   "source": [
    "### Шаг 6.  (**0.5 балла**)\n",
    "Теперь примените линейную регрессию с L1-регуляризацией (Lasso) для данной задачи. Объявите модель и подберите параметр регуляризации alpha по сетке. Ищите alpha в диапазоне (0.1, 1.1) с шагом 0.1.\n",
    "\n",
    "Осуществите подбор параметра alpha по тренировочным данным (Xtrain, ytrain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.1, Train MSE: 0.4774, Train R²: 0.2698\n",
      "alpha=0.2, Train MSE: 0.5185, Train R²: 0.2070\n",
      "alpha=0.3, Train MSE: 0.5648, Train R²: 0.1361\n",
      "alpha=0.4, Train MSE: 0.6295, Train R²: 0.0371\n",
      "alpha=0.5, Train MSE: 0.6316, Train R²: 0.0339\n",
      "alpha=0.6, Train MSE: 0.6317, Train R²: 0.0338\n",
      "alpha=0.7, Train MSE: 0.6318, Train R²: 0.0336\n",
      "alpha=0.8, Train MSE: 0.6319, Train R²: 0.0334\n",
      "alpha=0.9, Train MSE: 0.6321, Train R²: 0.0332\n",
      "alpha=1.0, Train MSE: 0.6323, Train R²: 0.0329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "best_alpha = ''\n",
    "best_r2 = float('inf')  \n",
    "results = []\n",
    "\n",
    "for alpha in np.arange(0.1, 1.1, 0.1):\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_tr = lasso.predict(X_train)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, y_pred_tr)\n",
    "    train_r2 = r2_score(y_train, y_pred_tr)\n",
    "\n",
    "    results.append((alpha, train_mse, train_r2)) \n",
    "\n",
    "    print(f'alpha={alpha:.1f}, Train MSE: {train_mse:.4f}, Train R²: {train_r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KZC5uOQ17YG"
   },
   "source": [
    "### Шаг 7.  (**0.5 балла**)\n",
    "Выведите наилучший алгоритм и наилучшее качество по результатам подбора alpha (best_estimator_ и best_score_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "HZBo6bZY17YG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator : Lasso(alpha=0.1)\n",
      "Best score (R²): 0.26162552533012484\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0.1, 1.1, 0.1) \n",
    "params = {'alpha': alphas}\n",
    "\n",
    "cv = GridSearchCV(lasso, params, scoring='r2', cv=5)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print('Best estimator :', cv.best_estimator_)\n",
    "print('Best score (R²):', cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJghumt117YH"
   },
   "source": [
    "### Шаг 8.  (**0.5 балла**)\n",
    "\n",
    "С помощью найденного best_estimator_ сделайте предсказание на тестовых данных и выведите на экран r2-score на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BBMQvQs817YH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² на тестовых данных: 0.1886\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = cv.best_estimator_.predict(X_test)\n",
    "test_r2_score = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f'R² на тестовых данных: {test_r2_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sKZz1LK17YI"
   },
   "source": [
    "### Шаг 9.  (**0.5 балла**)\n",
    "\n",
    "Попробуем улучшить качество модели за счет добавления полиномиальных признаков. Создайте pipeline, состоящий из добавления полиномиальных признаков степени 2, а затем применения линейной регрессии.\n",
    "\n",
    "Затем вычислите r2-score этой модели на кросс валидации с пятью фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "xcgzVSsM17YI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R²: 0.23009616946201242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "linear_pipe = Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "                       ('linear_model', LinearRegression())])\n",
    "print('R²:', cross_val_score(linear_pipe, X, y, cv=5, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHdHiMQ_17YJ"
   },
   "source": [
    "### Шаг 10.  (**0.5 балла**)\n",
    "Обучите модель (pipeline) на тренировочных данных и сделайте предсказания для train и test, затем выведите на экран r2-score и MSE на тренировочных и на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jBjwIal-17YK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE на тренировочных данных: 1.4545\n",
      "MSE на тестовых данных: 1.7488\n",
      "R² на тренировочных данных: -1.2248\n",
      "R² на тестовых данных: -1.7065\n"
     ]
    }
   ],
   "source": [
    "linear_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_pipe = linear_pipe.predict(X_train)\n",
    "y_pred_test_pipe = linear_pipe.predict(X_test)\n",
    "\n",
    "print(f\"MSE на тренировочных данных: {mean_squared_error(y_train, y_pred_train_pipe):.4f}\")\n",
    "print(f\"MSE на тестовых данных: {mean_squared_error(y_test, y_pred_test_pipe):.4f}\")\n",
    "print(f\"R² на тренировочных данных: {r2_score(y_train, y_pred_train_pipe):.4f}\")\n",
    "print(f\"R² на тестовых данных: {r2_score(y_test, y_pred_test_pipe):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RYZ62Uo17YK"
   },
   "source": [
    "### Сделайте выводы. Для этого ответьте на вопросы: (**1 балл**)\n",
    "\n",
    "1) Хорошее ли качество показала исходная модель (линейная регрессия без регуляризации)? Является ли эта модель переобученной?\n",
    "\n",
    "2) Помогла ли L1-регуляризация улучшить качество модели?\n",
    "\n",
    "3) Помогло ли добавление полиномов второй степени улучшить качество модели? Как добавление новых признаков повлияло на переобучение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLr_PQQt17YL"
   },
   "source": [
    "#### 1. Оценка линейной модели без регуляризации\n",
    "Линейная модель без регуляризации показала себя не очень хорошо. Значение R² меньше 0.5 говорит о том, что модель не справляется с задачей. Однако трудно точно сказать, есть ли переобучение. Мы видим лишь небольшое ухудшение метрики на тестовой выборке (около 0.1) по сравнению с обучающей. Различия между ошибками и значениями R² тоже невелики, так что делать однозначные выводы о переобучении сложно. К тому же, если поменять параметр random_state, результаты немного меняются, что тоже не указывает на переобучение.\n",
    "\n",
    "#### 2. Влияние L1-регуляризации на качество модели\n",
    "Что касается L1-регуляризации, то она не помогла улучшить модель. R² упал до 0.26, что хуже, чем у исходной модели. Это может означать, что регуляризация не смогла компенсировать снижение качества, и, похоже, не устранила признаки переобучения.\n",
    "\n",
    "#### 3. Эффект добавления полиномиальных признаков\n",
    "Добавление полиномов значительно ухудшило качество модели. На тренировочных данных R² стал отрицательным (-1.2248), что говорит о том, что модель не объясняет дисперсию данных и делает предсказания хуже, чем просто среднее значение целевой переменной.\n",
    "На тестовых данных результат ещё хуже R² = -1.7065. \n",
    "\n",
    "Это явное переобучение — модель слишком сложна для данных, добавленные полиномиальные признаки привели к сильному увеличению ошибки как на тренировочных, так и на тестовых данных. Модель слишком точно подогналась под тренировочные данные, что привело к сильному снижению её обобщающей способности на тестовых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o-lDGMS17YL"
   },
   "source": [
    "### *Попытайтесь улучшить модель (добейтесь наилучшего качества) - можно использовать любые методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euSZN9aj17YM"
   },
   "source": [
    "При улучшении качества r2 на 0.1-0.2 +1 балл, при большем улучшении +2 балла (дополнительно к 5 баллам за основную часть)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда ~~мы с чатом гпт~~ я работала над улучшением качества модели, наткнулась на интересный метод под названием **Voting Regressor**.  \n",
    "(супер много вариантов перепробовала, этот единственный дал хоть что-то относительно существенное)\n",
    "\n",
    "Как я поняла, **Voting Regressor** работает следующим образом: он обучает несколько моделей на одних и тех же данных, а затем комбинирует их предсказания. Например, в моей реализации я взяла простую линейную регрессию и случайный лес — два довольно разных подхода. Вместо того чтобы полагаться на одну из этих моделей, **Voting Regressor** усредняет их предсказания, что помогает снизить ошибку и улучшить обобщающую способность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "k527OrgK17YN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor R²: 0.3765221267960679\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor\n",
    "\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('lr', LinearRegression()),\n",
    "    ('rf', RandomForestRegressor(n_estimators=100))\n",
    "])\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "y_pred_test_voting = voting_regressor.predict(X_test)\n",
    "\n",
    "print('Voting Regressor R²:', r2_score(y_test, y_pred_test_voting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq9VJY3117YN"
   },
   "source": [
    "## Часть 2. Target encoding (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед проверкой!\n",
    "\n",
    "Я часто пользовалась Chat GPT: просила его объяснить все моменты, много уточняющих вопросов задавала, но еще сильно помогли интрукции, которые до заданий. Спасибо за них!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q08IEgtr17YO"
   },
   "source": [
    "В этом части домашнего задания вы будете работать с выборкой `1C`. Вам нужно посчитать счетчики для `item_id` четырьмя способами:\n",
    "\n",
    "    1) При помощи KFold схемы;  \n",
    "    2) При помощи Leave-one-out схемы;\n",
    "    3) При помощи smoothing схемы;\n",
    "    4) При помощи expanding mean схемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AZ8ZwvP17YQ"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "X7oNha7017YS",
    "outputId": "3d61e9bf-5e85-438b-813a-a1626363265e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935844</th>\n",
       "      <td>10.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935845</th>\n",
       "      <td>09.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935846</th>\n",
       "      <td>14.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7459</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935847</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7440</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935848</th>\n",
       "      <td>03.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2935849 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  date_block_num  shop_id  item_id  item_price  target\n",
       "0        02.01.2013               0       59    22154      999.00     1.0\n",
       "1        03.01.2013               0       25     2552      899.00     1.0\n",
       "2        05.01.2013               0       25     2552      899.00    -1.0\n",
       "3        06.01.2013               0       25     2554     1709.05     1.0\n",
       "4        15.01.2013               0       25     2555     1099.00     1.0\n",
       "...             ...             ...      ...      ...         ...     ...\n",
       "2935844  10.10.2015              33       25     7409      299.00     1.0\n",
       "2935845  09.10.2015              33       25     7460      299.00     1.0\n",
       "2935846  14.10.2015              33       25     7459      349.00     1.0\n",
       "2935847  22.10.2015              33       25     7440      299.00     1.0\n",
       "2935848  03.10.2015              33       25     7460      299.00     1.0\n",
       "\n",
       "[2935849 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('/Users/kh11vika/Downloads/sales_train.csv.gz')\n",
    "sales.columns = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'target']\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pf2RAhgG17YV"
   },
   "outputs": [],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = []\n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'target':'sum'})\n",
    "\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKxPEUME17YX"
   },
   "source": [
    "### Mean encodings без регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAKXDv2P17YY"
   },
   "source": [
    "После проделанной технической работы, мы готовы посчитать счетчики для переменной `item_id`.\n",
    "\n",
    "Ниже приведены две реализации подсчета счетчиков без регуляризации. Можно использовать данный код в качестве стартовой точки для реализации различных техник регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDJIXqPJ17YZ"
   },
   "source": [
    "#### Способ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nP0txxgu17YZ",
    "outputId": "71675772-09fc-4c64-cbc5-28376a5966fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830386988621764\n"
     ]
    }
   ],
   "source": [
    "# Calculate a mapping: {item_id: target_mean}\n",
    "item_id_target_mean = all_data.groupby('item_id').target.mean()\n",
    "\n",
    "# In our non-regularized case we just *map* the computed means to the `item_id`'s\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mc7TQh6V17Yb"
   },
   "source": [
    "#### Способ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ujgcz3um17Yc",
    "outputId": "e218ca20-126f-4806-a18f-89fa33b8eb6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830386988621764\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "     Differently to `.target.mean()` function `transform`\n",
    "   will return a dataframe with an index like in `all_data`.\n",
    "   Basically this single line of code is equivalent to the first two lines from of Method 1.\n",
    "'''\n",
    "all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRCBHEWe17Yd"
   },
   "source": [
    "###  KFold схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRXNZsdL17Ye"
   },
   "source": [
    "Необходимо реализовать Kfold схему с пятью фолдами. Используйте KFold(5) из sklearn.model_selection.\n",
    "\n",
    "1. Разбейте данные на 5 фолдов при помощи `sklearn.model_selection.KFold` с параметром `shuffle=False`.\n",
    "2. Проитерируйтесь по фолдам: используйте 4 обучающих фолда для подсчета средних значений таргета по `item_id` и заполните этими значениями валидационный фолд на каждой итерации.\n",
    "\n",
    "Обратите внимание на **Способ 1** из примера. В частности, изучите, как работают функции map и pd.Series.map. Они довольно полезны во многих ситуациях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция: 0.4165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "item_target_enc = np.zeros(all_data.shape[0])\n",
    "\n",
    "for train_index, test_index in kf.split(all_data):\n",
    "    train_data = all_data.iloc[train_index]\n",
    "    test_data = all_data.iloc[test_index]\n",
    "    \n",
    "    item_id_target_mean = train_data.groupby('item_id')['target'].mean()\n",
    "    item_target_enc[test_index] = test_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "all_data['item_target_enc'] = item_target_enc\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "correlation = np.corrcoef(all_data['target'].values, all_data['item_target_enc'].values)[0][1]\n",
    "print(f'Корреляция: {correlation:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tkd5Scs17Yf"
   },
   "source": [
    "Ожидаемый ответ 0.4165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYVw71Yj17aG"
   },
   "source": [
    "### Leave-one-out схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ9BuEDM17aG"
   },
   "source": [
    "Необходимо реализовать leave-one-out схему . Учтите, если вы запустите код из первого задания, задав количество фолдов такое же как размер выборки, то вы, вероятно, получите правильный ответ, но ждать будете очень-очень долго.\n",
    "\n",
    "Для более быстрой реализации подсчета среднего таргета на всех объектах, кроме одного, вы можете:\n",
    "\n",
    "1. Вычислить суммарный таргет по всем объектам.\n",
    "2. Вычесть таргет конкретного объекта и разделить результат на `n_objects - 1`.\n",
    "\n",
    "Заметим, что пункт `1.` следует сделать для всех объектов. Также заметим, что пункт `2.` может быть реализован без циклов `for`.\n",
    "\n",
    "Здесь может оказаться полезной функция .transform из **Способа 2** из примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция: 0.4804\n"
     ]
    }
   ],
   "source": [
    "total_target_sum = all_data.groupby('item_id')['target'].transform('sum')\n",
    "n_objects = all_data.groupby('item_id')['target'].transform('size')\n",
    "\n",
    "all_data['item_target_enc'] = (total_target_sum - all_data['target']) / (n_objects - 1)\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "zakodirovannaya = all_data['item_target_enc']\n",
    "correlation = np.corrcoef(all_data['target'], zakodirovannaya)[0, 1]\n",
    "print(f'Корреляция: {correlation:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7-Nstj317aH"
   },
   "source": [
    "Ожидаемый ответ 0.4803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8Dzq8xW17aI"
   },
   "source": [
    "### Smoothing (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neuv-Vu317aI"
   },
   "source": [
    "Необходимо реализовать smoothing с $\\alpha = 100$. Используйте формулу:\n",
    "\n",
    "$\\frac{mean(target) \\cdot nrows + globalmean \\cdot \\alpha }{nrows + \\alpha}$,\n",
    "\n",
    "где $globalmean=0.3343$. Заметим, что `nrows` - это количество объектов, принадлежащих конкретной категории, а не количество строк в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "pwjuyAnv17aI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция: 0.4818\n"
     ]
    }
   ],
   "source": [
    "localmean = all_data.groupby('item_id').target.mean()  \n",
    "nrows = all_data.groupby('item_id').target.count()\n",
    "\n",
    "all_data['item_target_enc'] = all_data['item_id'].map((localmean * nrows + 0.3343 * 100) / (nrows + 100))\n",
    "\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)  \n",
    "zakodirovannaya = all_data['item_target_enc'].values\n",
    "\n",
    "correlation = np.corrcoef(all_data['target'].values, zakodirovannaya)[0][1] \n",
    "print(f'Корреляция: {correlation:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2gbXN7017aJ"
   },
   "source": [
    "Ожидаемый ответ 0.4818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4exEAIF17aJ"
   },
   "source": [
    "### Expanding mean схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inIMt53z17aJ"
   },
   "source": [
    "Необходимо реализовать *expanding mean* схему. Ее суть заключается в том, чтобы пройти по отсортированному в определенном порядке датасету (датасет сортируется в самом начале задания) и для подсчета счетчика для строки $m$ использовать строки от $0$ до $m-1$. Вам будет необходимо воспользоваться pandas функциями [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html) и [`cumcount`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.cumcount.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция: 0.5025\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data.sort_values(['date_block_num', 'shop_id', 'item_id'])\n",
    "\n",
    "cumulative_sum = all_data.groupby('item_id')['target'].cumsum()\n",
    "previous_target_sum = cumulative_sum - all_data['target']\n",
    "item_counts = all_data.groupby('item_id')['target'].cumcount()\n",
    "\n",
    "all_data['item_target_enc'] = previous_target_sum / item_counts\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True)\n",
    "\n",
    "zakodirovannaya = all_data['item_target_enc'].values  \n",
    "\n",
    "correlation = np.corrcoef(all_data['target'].values, zakodirovannaya)[0][1] \n",
    "print(f'Корреляция: {correlation:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jH2vnZx17aK"
   },
   "source": [
    "Ожидаемый ответ 0.5025"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
